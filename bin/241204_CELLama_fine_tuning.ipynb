{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df96192e-ac5f-4441-a2ad-3f2a010c8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b55491-0ef0-4486-b85d-33362edab0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tisch2_sub = sc.read_h5ad('/storage/sc_cancer_atlas/3CA/merged/merged_sc_atlas_preprocessed_scaled_subset_0.2.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf78cfe4-94e9-499f-8a9c-1f3663812493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use var.index for gene names\n",
    "gene_names = merged_tisch2_sub.var.index\n",
    "\n",
    "# Generate sentences describing top genes for each cell\n",
    "top_genes_texts = []\n",
    "for i in range(merged_tisch2_sub.shape[0]):\n",
    "    # Get indices of top 20 genes (sorted by expression value)\n",
    "    top_genes_indices = merged_tisch2_sub.X[i].argsort()[-20:][::-1]\n",
    "    top_genes = gene_names[top_genes_indices]\n",
    "    sentence = f\"Top genes are {', '.join(top_genes)}.\"\n",
    "    top_genes_texts.append(sentence)\n",
    "\n",
    "# Combine with cell types\n",
    "data = pd.DataFrame({\n",
    "    \"text\": top_genes_texts,\n",
    "    \"label\": merged_tisch2_sub.obs['cell_type_merged_coarse']\n",
    "})\n",
    "data = data.dropna()  # Drop rows with missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5369541d-ef22-40f3-a203-6a912db214e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['encoded_label'] = label_encoder.fit_transform(data['label'])\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1397f803-4b43-4311-bd23-e889732963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, stratify=data['encoded_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487b4461-b7ee-4ce2-8d8f-cb330d651d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401db94e-b829-4531-89c8-2fbabe5b6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터셋 및 데이터로더\n",
    "train_dataset = TextDataset(train_df['text'], train_df['encoded_label'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 테스트 데이터셋 및 데이터로더\n",
    "test_dataset = TextDataset(test_df['text'], test_df['encoded_label'])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ced3c6-32c9-4c94-b6ac-cc9253b6e1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SentenceTransformer 모델 로드\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 분류 헤드 추가\n",
    "classifier = nn.Linear(model.get_sentence_embedding_dimension(), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355bf209-d5bc-496a-ae0f-7bdebffef9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, model, classifier):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def forward(self, input_texts):\n",
    "        # 토크나이즈 및 입력 데이터 생성\n",
    "        input_features = self.model.tokenize(input_texts)\n",
    "        # 입력 데이터를 모델의 디바이스로 이동\n",
    "        input_features = {key: value.to(self.model.device) for key, value in input_features.items()}\n",
    "        # SentenceTransformer 모델을 통해 임베딩 추출\n",
    "        embeddings = self.model(input_features)['sentence_embedding']\n",
    "        # 분류 헤드를 통해 로짓 계산\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306caebe-d872-48b6-9a95-0138cbd5f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "    (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "    (2): Normalize()\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model = ClassificationModel(model, classifier)\n",
    "# GPU 사용 가능 시 모델을 GPU로 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc4b919-6d81-4ded-8f70-b776499d5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(classification_model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bade2a1a-c307-481a-abeb-866fcb4f9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████| 5875/5875 [04:40<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9273898255977224\n",
      "Epoch 1, Validation Accuracy: 0.5514255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████| 5875/5875 [04:40<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.4651445059979216\n",
      "Epoch 2, Validation Accuracy: 0.5834680851063829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████| 5875/5875 [04:41<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.283619684665761\n",
      "Epoch 3, Validation Accuracy: 0.5891702127659575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████| 5875/5875 [04:44<00:00, 20.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.1965293184036905\n",
      "Epoch 4, Validation Accuracy: 0.5985744680851064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████| 5875/5875 [04:45<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.1469673238206417\n",
      "Epoch 5, Validation Accuracy: 0.601531914893617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████| 5875/5875 [04:43<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.1138788581604653\n",
      "Epoch 6, Validation Accuracy: 0.5992765957446808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████| 5875/5875 [04:44<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.0905856708313557\n",
      "Epoch 7, Validation Accuracy: 0.6057021276595744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████| 5875/5875 [04:43<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.0699980573400538\n",
      "Epoch 8, Validation Accuracy: 0.6044255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████| 5875/5875 [04:44<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.0525244386196138\n",
      "Epoch 9, Validation Accuracy: 0.6082127659574468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████| 5875/5875 [04:45<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.036445513202789\n",
      "Epoch 10, Validation Accuracy: 0.6055531914893617\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classification_model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in tqdm(train_dataloader, desc=f'Epoch {epoch+1}'):\n",
    "        labels = labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = classification_model(texts)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_loss}')\n",
    "    \n",
    "    # 평가\n",
    "    classification_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_dataloader:\n",
    "            labels = labels.to(device).long()\n",
    "            logits = classification_model(texts)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}, Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8607c3-7294-4a44-8c6d-808740cb6a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "    (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "    (2): Normalize()\n",
       "  )\n",
       "  (classifier): Linear(in_features=384, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장\n",
    "torch.save(classification_model.state_dict(), 'classification_model.pt')\n",
    "\n",
    "# 모델 로드\n",
    "classification_model = ClassificationModel(model, classifier)\n",
    "classification_model.load_state_dict(torch.load('classification_model.pt'))\n",
    "classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e8d7816-34f6-46de-865c-7b666f858439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████████████████| 234997/234997 [14:19<00:00, 273.40it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     predicted_labels\u001b[38;5;241m.\u001b[39mappend(predicted_label_encoded)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 성능 지표 계산\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(true_labels, predicted_labels)\n\u001b[1;32m     27\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(true_labels, predicted_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(true_labels, predicted_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_label(text):\n",
    "    classification_model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = classification_model([text])\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predicted_label_id = torch.argmax(probabilities, dim=1).item()\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_id])[0]\n",
    "    return predicted_label\n",
    "\n",
    "# 실제 라벨 (인코딩된 라벨)\n",
    "true_labels = data['encoded_label'].values\n",
    "\n",
    "# 예측 라벨을 저장할 리스트\n",
    "predicted_labels = []\n",
    "\n",
    "# 데이터셋의 텍스트 리스트\n",
    "texts = data['text'].tolist()\n",
    "\n",
    "# 예측 수행\n",
    "for text in tqdm(texts, desc='Predicting'):\n",
    "    predicted_label = predict_label(text)\n",
    "    predicted_label_encoded = label_encoder.transform([predicted_label])[0]\n",
    "    predicted_labels.append(predicted_label_encoded)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(\"모델 성능 평가:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 자세한 분류 보고서 출력\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5c494a-7d66-4c77-a04b-84b647ddfc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 평가:\n",
      "Accuracy: 0.6409\n",
      "Precision (Weighted): 0.7988\n",
      "Recall (Weighted): 0.6409\n",
      "F1 Score (Weighted): 0.6579\n",
      "\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "            B       0.91      0.72      0.80     12542\n",
      "   Epithelial       0.90      0.72      0.80     19782\n",
      "   Fibroblast       0.75      0.85      0.80      4254\n",
      "Immune_Others       0.00      0.00      0.00       227\n",
      "    Lymphatic       0.18      0.02      0.03       117\n",
      "     Lymphoid       0.72      0.41      0.52      3497\n",
      "    Malignant       0.36      0.98      0.53     41852\n",
      "      Myeloid       0.94      0.55      0.69     39891\n",
      "         NK_T       0.92      0.62      0.74     62783\n",
      "       Others       0.00      0.00      0.00        92\n",
      "      Stromal       0.79      0.26      0.40     17614\n",
      "     Vascular       0.86      0.59      0.70     11623\n",
      "          nan       0.89      0.43      0.58     20723\n",
      "\n",
      "     accuracy                           0.64    234997\n",
      "    macro avg       0.63      0.47      0.51    234997\n",
      " weighted avg       0.80      0.64      0.66    234997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(\"모델 성능 평가:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 자세한 분류 보고서 출력\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26651d-3349-4ed2-a246-7c23093349ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d591e-8cac-42c2-9652-fc8e35ad6fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b832fbb5-6de6-4137-a1d9-c639efd16be2",
   "metadata": {},
   "source": [
    "## Fine-tuning 하기 전의 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ca3936-6e68-40fb-b86b-156183e0744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 사전 학습된 모델 로드\n",
    "pretrained_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 데이터셋 임베딩 생성 (훈련 및 테스트)\n",
    "train_embeddings = pretrained_model.encode(train_df['text'].tolist(), convert_to_tensor=True)\n",
    "test_embeddings = pretrained_model.encode(test_df['text'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "471e00f8-dd6d-47bd-9b2f-e683eca26803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 분류기 학습\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "classifier.fit(train_embeddings.cpu().numpy(), train_df['encoded_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ee5e6c-0cb9-4b21-b85a-0fc85edf8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained 모델 성능 평가:\n",
      "Accuracy: 0.4465\n",
      "Precision (Weighted): 0.5205\n",
      "Recall (Weighted): 0.4465\n",
      "F1 Score (Weighted): 0.4280\n",
      "\n",
      "분류 보고서:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "            B       0.64      0.20      0.30      2508\n",
      "   Epithelial       0.54      0.37      0.44      3957\n",
      "   Fibroblast       0.64      0.39      0.49       851\n",
      "Immune_Others       0.00      0.00      0.00        45\n",
      "    Lymphatic       0.00      0.00      0.00        23\n",
      "     Lymphoid       0.78      0.23      0.36       699\n",
      "    Malignant       0.32      0.85      0.46      8371\n",
      "      Myeloid       0.59      0.36      0.45      7978\n",
      "         NK_T       0.55      0.54      0.55     12557\n",
      "       Others       0.00      0.00      0.00        18\n",
      "      Stromal       0.55      0.13      0.21      3523\n",
      "     Vascular       0.53      0.20      0.29      2325\n",
      "          nan       0.50      0.21      0.29      4145\n",
      "\n",
      "     accuracy                           0.45     47000\n",
      "    macro avg       0.44      0.27      0.30     47000\n",
      " weighted avg       0.52      0.45      0.43     47000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jeongbinpark/miniconda3/envs/cellama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 예측\n",
    "test_predictions = classifier.predict(test_embeddings.cpu().numpy())\n",
    "\n",
    "# 성능 지표 계산\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(test_df['encoded_label'], test_predictions)\n",
    "precision = precision_score(test_df['encoded_label'], test_predictions, average='weighted')\n",
    "recall = recall_score(test_df['encoded_label'], test_predictions, average='weighted')\n",
    "f1 = f1_score(test_df['encoded_label'], test_predictions, average='weighted')\n",
    "\n",
    "print(\"Pretrained 모델 성능 평가:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 자세한 분류 보고서 출력\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(test_df['encoded_label'], test_predictions, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0275e-3529-4cc4-8ef8-85d41cecbbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
